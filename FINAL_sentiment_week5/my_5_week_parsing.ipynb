{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from multiprocessing import Pool\n",
    "import codecs\n",
    "import sys\n",
    "#import contextlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_list = [\"https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff\",\n",
    "            \"https://en.wikipedia.org/wiki/Category:Machine_learning_algorithms\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_1 = requests.get(url_list[0]).text\n",
    "parser_1 = bs4.BeautifulSoup(text_1, 'lxml')\n",
    "x_1 = parser_1.findAll(\"h1\")\n",
    "result_1 = [res.text for res in x_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join(result_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with codecs.open('wiki_bias_h1_header.txt', 'w', 'utf-8') as output_file:\n",
    "    if sys.version_info >= (3, 0):\n",
    "        ''' python 3 '''\n",
    "        print(s, end=\"\", file=output_file)\n",
    "    else:\n",
    "        ''' python 2 '''\n",
    "        print >> output_file, u'\\n'.join(result_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_2 = requests.get(url_list[1]).text\n",
    "parser_2 = bs4.BeautifulSoup(text_2, 'lxml')\n",
    "result_2 = []\n",
    "for div in parser_2.find_all(\"div\", attrs={'id':'mw-pages'}):\n",
    "    for li in div.find_all('li'):\n",
    "        a = li.find('a')\n",
    "        #a['href'], a.get_text()\n",
    "        result_2.append(a.get_text())       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#div = parser.find(\"div\", attrs={\"class\": \"mw-category\"})\n",
    "#pages = div.findAll('a')\n",
    "#for s in pages:     #РІС‹РІРѕРґРёРј С‚СЂРµР±СѓРµРјС‹Р№ СЃРїРёСЃРѕРє\n",
    "#        print s.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join(result_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with codecs.open('machine_learning_algorithms.txt', 'w', 'utf-8') as output_file:\n",
    "    if sys.version_info >= (3, 0):\n",
    "        ''' python 3 '''\n",
    "        print(s, end=\"\", file=output_file)\n",
    "    else:\n",
    "        ''' python 2 '''\n",
    "        print >> output_file, u'\\n'.join(result_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
